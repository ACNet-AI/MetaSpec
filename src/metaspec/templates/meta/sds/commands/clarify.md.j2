---
description: Interactive clarification workflow - ask up to 5 targeted questions to resolve specification ambiguities (inspired by spec-kit)
---

## User Input

```text
$ARGUMENTS
```

You **MUST** consider the user input before proceeding (if not empty).

## Goal

Detect and reduce ambiguity or missing decisions in the domain specification through **interactive questioning**. This command runs BEFORE `/metaspec.sds.plan`.

**Key Philosophy** (inspired by spec-kit):
- Ask ONE question at a time (not a batch report)
- AI recommends the best option for each question
- Maximum 5 questions to avoid user fatigue
- Integrate answers incrementally into spec.md

---

## Execution Flow

### 1. Load specification

**Read specification**:
```bash
specs/domain/{spec_id}-{name}/spec.md
```

**If missing**: Instruct user to run `/metaspec.sds.specify` first.

---

### 2. Perform ambiguity scan

**Scan specification using taxonomy**. Mark each category: **Clear** / **Partial** / **Missing**.

**Taxonomy Categories**:

#### **Entity Design Clarity**
- Are all entity fields defined with types (string, number, boolean, array, object)?
- Are required vs optional fields clear?
- Are field descriptions specific (not vague like "data", "info")?
- Are field constraints documented (enum, format, range)?
- Are example values provided?

#### **Validation Rules Completeness**
- Are structural validation rules (type, required) defined?
- Are semantic validation rules (cross-field, business logic) specified?
- Are domain-specific validation rules documented?
- Are error message formats specified?
- Can validation rules be objectively tested?

#### **Operations Specification**
- Are all operations listed with clear purposes?
- Are request and response schemas defined?
- Are success and error response formats documented?
- Are operation examples provided?
- Are operation constraints specified (timeout, rate limit)?

#### **Error Handling**
- Are all error codes defined with meanings?
- Are error response formats consistent?
- Are error messages descriptive and actionable?
- Are recovery strategies specified?

#### **Examples & Documentation**
- Are examples provided for all entities?
- Are examples provided for all operations?
- Do examples cover success and error cases?
- Are examples valid against schemas?

#### **Constitution Alignment**
- Does entity design follow Entity-First principle (3-5 core fields)?
- Are entity field names self-explanatory?
- Is specification minimal (only essential operations)?
- Are specifications AI-friendly (clear descriptions)?

#### **Domain Constraints**
- Are domain-specific constraints documented?
- Are data volume/scale assumptions stated?
- Are performance expectations specified?
- Are compliance/regulatory requirements noted?

#### **Terminology Consistency**
- Are canonical terms defined?
- Is terminology consistent across sections?
- Are ambiguous adjectives ("fast", "robust") quantified?

**Build internal coverage map** (do not output unless no questions).

---

### 3. Generate prioritized question queue

**Prioritization algorithm** (spec-kit inspired):
```
Priority = Impact × Uncertainty

Impact scores:
- CRITICAL (4): Blocks implementation, affects architecture
- HIGH (3): Affects multiple components, testability
- MEDIUM (2): Affects single component, clarity
- LOW (1): Style, minor improvement

Uncertainty scores:
- Missing (3): No information
- Partial (2): Incomplete information
- Vague (2): Ambiguous information
- Clear (0): Sufficient information
```

**Question generation rules**:
1. Select top 5 questions by Priority score
2. Ensure category diversity (avoid 3+ questions from same category)
3. Format as multiple-choice (2-5 options) OR short-answer (≤5 words)
4. For each question, AI must analyze and recommend best option

**If no high-priority questions exist**: Report "No critical ambiguities detected" and skip to step 7.

---

### 4. Interactive questioning loop

**Present EXACTLY ONE question at a time.**

#### **For multiple-choice questions**:

**Step 1: Analyze options**
- Evaluate each option against best practices
- Consider project type, domain standards, risk factors
- Determine the most suitable option

**Step 2: Present question with recommendation**

```markdown
**Question {n}/5: {question}**

**Recommended:** Option {X} - {option_text}

**Reasoning:** {1-2 sentences explaining why this is best}
- {reason 1}
- {reason 2}

| Option | Description |
|--------|-------------|
| A | {option_a_description} |
| B | {option_b_description} ← Recommended |
| C | {option_c_description} |
| Short | Provide your own answer (≤5 words) |

**Reply**: Option letter (e.g., "B"), "yes"/"recommended" to accept, or custom answer.
```

#### **For short-answer questions**:

```markdown
**Question {n}/5: {question}**

**Suggested:** {suggested_answer}

**Reasoning:** {1-2 sentences explaining suggestion}

**Format**: Short answer (≤5 words)

**Reply**: "yes"/"suggested" to accept, or provide your own answer.
```

#### **Process user answer**:

1. **If user says** "yes", "recommended", "suggested":
   - Use your stated recommendation/suggestion

2. **If user provides option letter** (A/B/C):
   - Validate it matches available options
   - If invalid, ask for clarification (doesn't count as new question)

3. **If user provides custom answer**:
   - Validate length (≤5 words for short-answer)
   - If too long, ask for concise version (doesn't count as new question)

4. **Once answer accepted**:
   - Record in working memory
   - Immediately integrate into spec.md (see step 5)
   - Move to next question

#### **Stop conditions**:

- All 5 questions answered
- User says "done", "stop", "skip" (accept partial completion)
- All critical ambiguities resolved (remaining questions become unnecessary)

**Never reveal future queued questions in advance.**

---

### 5. Integration after EACH accepted answer

**Incremental update approach** (spec-kit inspired):

#### **First answer in session**:

1. **Ensure `## Clarifications` section exists**:
   - If missing, create after `## Overview` or `## Context` section
   
2. **Create today's session subsection**:
   ```markdown
   ### Session {YYYY-MM-DD}
   ```

#### **For every answer**:

1. **Append to Clarifications**:
   ```markdown
   - Q: {question} → A: {answer}
   ```

2. **Apply to appropriate section** (based on question category):

   **Entity Design** → Update `## Entities` section:
   - Add/modify entity fields with types
   - Add field constraints
   - Add examples
   
   **Validation Rules** → Update `## Validation Rules` section:
   - Add specific validation rules
   - Define error codes
   - Specify error messages
   
   **Operations** → Update `## Operations` section:
   - Add operation details
   - Define request/response schemas
   - Add constraints (timeout, rate limit)
   
   **Error Handling** → Update `## Error Handling` section:
   - Define error codes
   - Specify error formats
   - Add recovery strategies
   
   **Examples** → Update `## Examples` section:
   - Add entity examples
   - Add operation examples
   - Add edge case examples
   
   **Constitution** → Update relevant sections:
   - Adjust entity design
   - Add principle justifications
   
   **Domain Constraints** → Update `## Domain Constraints` section:
   - Add performance targets
   - Add scale assumptions
   - Add compliance requirements
   
   **Terminology** → Normalize across all sections:
   - Replace old term with canonical term
   - Add glossary entry if needed

3. **Remove contradictions**:
   - If answer invalidates earlier statement, replace (don't duplicate)
   - Remove vague placeholders now clarified

4. **Save spec.md immediately** (atomic write after each integration)

5. **Preserve formatting**:
   - Maintain heading hierarchy
   - Don't reorder unrelated sections
   - Keep consistent markdown style

---

### 6. Validation (after EACH write)

**Check**:
- ✅ Clarifications section has one bullet per answer
- ✅ Updated section contains no lingering vague terms
- ✅ No contradictory statements remain
- ✅ Markdown structure valid
- ✅ Terminology consistent across sections

**If validation fails**: Fix immediately before next question.

---

### 7. Report completion

**After questioning loop ends**:

```markdown
## ✅ Clarification Session Complete

**Summary**:
- Questions asked & answered: {n}/5
- Specification updated: specs/domain/{spec_id}-{name}/spec.md
- Sections touched: {list_of_sections}

**Coverage Status**:

| Category | Before | After | Status |
|----------|--------|-------|--------|
| Entity Design | Partial | Clear | ✅ Resolved |
| Validation Rules | Missing | Clear | ✅ Resolved |
| Operations | Clear | Clear | ✅ Already sufficient |
| Error Handling | Partial | Partial | ⚠️ Deferred (low impact) |
| Examples | Missing | Partial | ⚠️ Outstanding |
| Constitution | Clear | Clear | ✅ Already sufficient |
| Domain Constraints | Partial | Clear | ✅ Resolved |
| Terminology | Clear | Clear | ✅ Already sufficient |

**Impact**:
- Resolved: {n} categories (was Partial/Missing, now Clear)
- Deferred: {n} categories (low impact, better for planning phase)
- Outstanding: {n} categories (still Partial/Missing but within question limit)

**Recommendation**:
{if no_outstanding_critical}
  ✅ Ready to proceed to `/metaspec.sds.plan`
{else}
  ⚠️ Consider running `/metaspec.sds.clarify` again to address:
  - {outstanding_category_1}
  - {outstanding_category_2}
  
  OR proceed to `/metaspec.sds.plan` (accept minor ambiguities)
{endif}

**Next Command**: `/metaspec.sds.plan`
```

---

## Special Cases

### **No ambiguities found**:

```markdown
## ✅ No Critical Ambiguities Detected

**Coverage Summary**:
All categories marked **Clear** - specification is well-defined.

| Category | Status |
|----------|--------|
| Entity Design | ✅ Clear |
| Validation Rules | ✅ Clear |
| Operations | ✅ Clear |
| Error Handling | ✅ Clear |
| Examples | ✅ Clear |
| Constitution | ✅ Clear |
| Domain Constraints | ✅ Clear |
| Terminology | ✅ Clear |

**Recommendation**: Proceed to `/metaspec.sds.plan`
```

### **User skips clarification**:

Accept early termination:
```markdown
⚠️ Clarification skipped by user after {n} questions.

**Warning**: Proceeding with unresolved ambiguities increases downstream rework risk.

**Deferred categories**:
- {category_1}: {brief_issue}
- {category_2}: {brief_issue}

You can:
1. Run `/metaspec.sds.clarify` again later
2. Proceed to `/metaspec.sds.plan` and address during planning

**Next Command**: `/metaspec.sds.plan` (proceed with caution)
```

---

## Operating Principles

### **Token Efficiency** (spec-kit inspired):

- **Progressive disclosure**: Load spec once, build internal model
- **Minimal output**: Only show current question, not full queue
- **Structured answers**: Multiple-choice or short-answer only
- **Incremental writes**: Update spec after each answer (avoid large final merge)

### **User Experience**:

- **One question at a time**: Reduce cognitive load
- **AI recommendations**: Lower decision cost
- **Immediate feedback**: See spec update after each answer
- **Flexible termination**: Accept partial completion

### **Quality Assurance**:

- **Prioritization**: Focus on high-impact ambiguities first
- **Category diversity**: Avoid question clustering
- **Validation**: Check consistency after each integration
- **Deterministic**: Same spec state → same priority order

---

## Context

{ARGS}
